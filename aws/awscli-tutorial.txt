Created an all-in-one guide in the wiki on building a Linux/RHEL Infrastructure in AWS with the aws cli, Puppet, and Terraform. Any feedback is appreciated!  

tl;dr: Fork repo. Run terraform init github.com/hashicorp/terraform/examples/aws-tw. Run terraform apply -var 'key_name=terraform' -var 'key_path=/Users/jsmith/.ssh/terraform.pem' where that's your aws key. Boom. One overly engineered dogecoin mining operation for you.  

### INTRO 

This page is meant to document useful information related to AWS. We'll be documenting commands by running through the creation of a basic build out that'll include VPCs, subnets, security groups, naming conventions, and AMIs and the like, after which I'll add a Terraform configuration to tie it all together and how to plan it out. The network diagram for the build is currently located [here](https://github.com/SouthernAirTemple/reddit-wiki/blob/master/aws/reddit-supercloud.png) but may be subject to change. The primary goal is to make this as exportable as possible by ensuring we use generic RHEL images instead of AWS NAT ones and building the subnet around that, and using Terraform instead of something like CloudFormation or OpsWorks. I also highly recommend using any prefered kanban app for schedule management with breaking down these tasks, something like a couple instances a day broken down into individual tasks if you want to take it slow.  

Also, if you want to just grab the terraform files feel free to apply your heart out. :>)  

### PREREQUISITES

Make sure you use ssh-agent agent command and set *bastion* for forwarding in /etc/ssh_config, and use your personal /etc/hosts file to configure the bastion server name and IP. 

See variables.sh file and modify and export as needed. 

### INITIAL CONFIG

1) Setting the hostname with cloud-init

AWS (and Rackspace, actually) uses cloud-init config management tool (think Ansible for Cloud Providers. Uses YAML format) to set the hostname and other initial host settings. Just run the following command to ensure the host name gets set:

    sudo sh -c "echo '# /etc/cloud/cloud.cfg.d/defaults.cfg
    # cloud-config
    # hostname reverts if not added 
    hostname: myhostname
    fqdn: myhostname.mydomainname' > /etc/cloud/cloud.cfg.d/defaults.cfg"

2) Configure aws cli

You can view the exact region name to use by visiting http://docs.aws.amazon.com/general/latest/gr/rande.html#ec2_region. When it asks you which region, copy-paste the field right next to Region Name. For Us East, use us-east-1 for the name. Use default text output format so our eyes don't bleed. Speaking of which, enjoy this one-liner:  

     aws configure set access_key "$(cat $CREDENTIALS|tr '" ,' " "|awk '{print $2}'|tail -n1)" && aws configure set secret_key "$(cat $CREDENTIALS|tr '" ,' " "|awk '{print $1}'|tail -n1)" && aws configure set region $EC2_REGION && rm -f $CREDENTIALS

### VPC & ROUTE TABLE 

Create the 10.0.0.0/16 VPC we'll be using with default tenancy so we don't get charged for dedicated hardware.

    aws ec2 create-vpc --cidr-block 10.0.0.0/16 --instance-tenancy default

Change the name to $ORG_NAME. Your vpc id is returned from above (vpc-123456) 

    aws ec2 create-tags --resource $VPC_ID --tag "Value=$ORG_NAME,Key=Name"

Create an internet gateway to the 10.0.0.0/16 VPC, enabling public internet access. Set value of IG_ID to returned value from first command. This prints only the internet gateway ID with awk.  

    aws ec2 create-internet-gateway|awk '{print $2}'
    aws ec2 create-tags --resource $IG_ID --tag "Value=$ORG_NAME,Key=Name"
    aws ec2 attach-internet-gateway --internet-gateway-id $IG_ID --vpc-id $VPC_ID

Associate default route table for 10.0.0.0/16 network to 10.0.1.0/24 subnet
    # using built-in filter might be faster if this list was huge. 
    aws ec2 describe-vpcs|grep $ORG_NAME -B1
    aws ec2 describe-subnets|grep $ORG_NAME -B1
    aws ec2 describe-route-tables|grep $VPC_ID
    aws ec2 create-tags --resource $RT_ID --tag "Value=$ORG_NAME,Key=Name"

Create new route going from our route table to internet gateway
    
    aws ec2 create-route --route-table-id $RT_ID --destination-cidr-block 0.0.0.0/0 --gateway-id $GW_ID 

### SUBNETTING

Create the 10.0.1.0/24 subnet and change to $ORG_NAME. Note the minimum host address we can use outside of the reserved range is 10.0.1.4. 

    aws ec2 create-subnet --vpc-id $VPC_ID --cidr-block 10.0.1.0/24
    aws ec2 create-tags --resource $SUB_ID --tag "Value=$ORG_NAME-$ENV_STATUS,Key=Name"

### S3 

We're going to be working with S3 here to create our backups. There will be 3 buckets; configs, files, dbs

    # this will be used to store our config files like Puppet config and CA
    aws s3api create-bucket --bucket zombocomconfigs --create-bucket-configuration LocationConstraint=us-west-1 

    aws s3api create-bucket --bucket zombocomfiles --create-bucket-configuration LocationConstraint=us-west-1

### IAM 

We're going to create 3 IAM groups and users that belong to that group which'll allow S3 access and back up our wordpress database to the cloud each night. In the even a server goes away, it'll be a matter of spinning up a clone, grabbing the database, and importing the data. If a server requires both files and config access, for example, multiple profiles can be used with aws cli in ~/.aws/credentials. These credentials will be stored as their own nfs shares in /etc/exports (e.g. /data/aws/config/creds.txt, /data/aws/access/creds.txt, /data/aws/dbs/creds.txt)

1) Create 3 new users for files, config, and dbs.

    aws iam create-user --user-name S3ConfigAccess
    aws iam create-user --user-name S3FileAccess
    aws iam create-user --user-name S3DBAccess

2) Create 3 new groups for files, config, and dbs with users added. 

    aws iam create-group --group-name S3ConfigAccess
    aws iam create-group --group-name S3FileAccess
    aws iam create-group --group-name S3DBAccess

3) Add each user created to their respective groups.

    aws iam add-user-to-group --user-name S3ConfigAccess --group-name S3ConfigAccess
    aws iam add-user-to-group --user-name S3FileAccess --group-name S3FileAccess
    aws iam add-user-to-group --user-name S3DBAccess --group-name S3DBAccess

4) Create S3 access policies

    aws iam create-policy --policy-name S3ConfigAccess --policy-document $RAWGITHUB/reddit-wiki/master/aws/stage/iam/configaccess.json
    aws iam create-policy --policy-name S3FileAccess --policy-document $RAWGITHUB/reddit-wiki/master/aws/stage/iam/fileaccess.json
    aws iam create-policy --policy-name S3DBAccess --policy-document $RAWGITHUB/reddit-wiki/master/aws/stage/iam/dbaccess.json

5) Attach access policies to group polices

    aws iam list-policies 2>&1|grep S3ConfigAccess
    aws iam attach-group-policy --group-name S3ConfigAccess --policy-arn arn:aws:iam::$IAM_ARN_ID:policy/S3ConfigAccess
    aws iam attach-group-policy --group-name S3FileAccess --policy-arn arn:aws:iam::$IAM_ARN_ID:policy/S3FileAccess
    aws iam attach-group-policy --group-name S3DBAccess --policy-arn arn:aws:iam::$IAM_ARN_ID:policy/S3DBAccess
    

### SECURITY GROUPS

Create the following security groups policies. SG_ID should be changed as needed:

1) monit-$ENV_STATUS-nagios => allow 22 from access-$ENV_STATUS-bastion.

    aws ec2 create-security-group --group-name monit-$ENV_STATUS-nagios --description "monitoring security group" --vpc-id $VPC_ID

2) sshlb-$ENV_STATUS-haproxy => allow all in on port 22 (forwarding port) and port 2222 (ssh on server). All from monit-$ENV_STATUS-nagios.

    aws ec2 create-security-group --group-name sshlb-$ENV_STATUS-haproxy --description "sshlb security group" --vpc-id $VPC_ID
    aws ec2 authorize-security-group-ingress --group-id $SG_ID --protocol tcp --port 22 --cidr 0.0.0.0/0
    aws ec2 authorize-security-group-ingress --group-id $SG_ID --protocol tcp --port 2222 --cidr 0.0.0.0/0
 
3) access-$ENV_STATUS-bastion => allow port 22 from sshlb-$ENV_STATUS-haproxy security group. All from monit-$ENV_STATUS-nagios.

    # change SG_ID to below result. $SG_IN to sshlb-$ENV_STATUS-haproxy ID. 

    aws ec2 create-security-group --group-name access-$ENV_STATUS-bastion --description "ssh access security group" --vpc-id $VPC_ID

    aws ec2 authorize-security-group-ingress --group-id $SG_ID --protocol tcp --port 22 --source-group "$SG_IN"

4) config-$ENV_STATUS-puppet-1a => allow ports 8140 for puppet agent access, 443 for pe console, 61613 for mcollective. 

    aws ec2 create-security-group --group-name config-$ENV_STATUS-puppet --description "puppet master security group" --vpc-id $VPC_ID 

    SG_ID="CHANGE_TO_ABOVE_RESULT"
    aws ec2 authorize-security-group-ingress --group-id $SG_ID --protocol tcp --port 22 --source-group "$SG_IN"
    aws ec2 authorize-security-group-ingress --group-id $SG_ID --protocol tcp --port 8140 --cidr $STAGE_NET
    aws ec2 authorize-security-group-ingress --group-id $SG_ID --protocol tcp --port 443 --cidr $STAGE_NET
    aws ec2 authorize-security-group-ingress --group-id $SG_ID --protocol tcp --port 61613 --cidr $STAGE_NET

5) storage-$ENV_STATUS-nfs-1a

    aws ec2 create-security-group --group-name storage-$ENV_STATUS-nfs --description "nfs security group" --vpc-id $VPC_ID

dhcp-$ENV_STATUS-dhcp => allow 22 from access-$ENV_STATUS-bastion. All for 67 and 68. All from monit-$ENV_SATUS-nagios. 
weblb-$ENV_STATUS-haproxy => allow all on port 80, 443. Allow 22 from access-$ENV_STATUS-bastion. All from monit-$ENV_STATUS-nagios.
web-$ENV_STATUS-nginx => allow 443,80 from weblb-$ENV_STATUS-haproxy. All from monit-$ENV_STATUS-nagios.
db-$ENV_STATUS-galera => allow 3306 from web-$ENV_STATUS-nginx. All from monit-$ENV_STATUS-nagios.

### INSTANCES

1) sshlb-$ENV_STATUS-haproxy-1a (t2.micro. 10GB) => load balancer for SSH bastion to access all other instances. Manually set INST_ID to instance id before tagging. Change $SG_ID to security group for each new instance created with unique group name for instance group (ex: aws ec2 describe-security-groups 2>&1|grep sshlb-stage-haproxy). 

    SG_ID=""
    aws ec2 run-instances --image-id $AMI_ID --count 1 --instance-type $INST_TYPE --key-name $KEY_NAME --security-group-ids $SG_ID --subnet-id $SUB_ID --associate-public-ip-address --private-ip-address 10.0.1.4 --block-device-mappings "[{\"DeviceName\": \"/dev/sdh\",\"Ebs\":{\"VolumeSize\":$DISK_SIZE}}]" --iam-instance-profile Name=$S3_CONF --user-data '#!/usr/bin/bash

'\ "yum install git -y
   git clone $GITREPO
   bash reddit-wiki/aws/$ENV_STATUS/ec2/defaults.sh
   bash reddit-wiki/aws/$ENV_STATUS/ec2/sshlb-$ENV_STATUS-haproxy/sshlb-$ENV_STATUS-haproxy-1a.sh
   mv reddit-wiki/aws/$ENV_STATUS/ec2/hosts /etc/hosts

   mv $GITHUB/stage/ec2/sshlb-stage-haproxy/haproxy.cfg /etc/haproxy/haproxy.cfg && systemctl restart haproxy"

    aws ec2 create-tags --resource $INST_ID --tag "Value=sshlb-$ENV_STATUS-haproxy-1a,Key=Name"
        

2) access-stage-bastion-1a => first ssh instance. Change SG_ID to the security id for the group. INST_ID to instance ID. 

    aws ec2 run-instances --image-id $AMI_ID --count 1 --instance-type $INST_TYPE --key-name $KEY_NAME --security-group-ids $SG_ID --subnet-id $SUB_ID --associate-public-ip-address --private-ip-address 10.0.1.6 --block-device-mappings "[{\"DeviceName\": \"/dev/sdh\",\"Ebs\":{\"VolumeSize\":$DISK_SIZE}}]" --iam-instance-profile Name=$S3_CONF --user-data '#!/usr/bin/bash

'\ "yum install git -y
   git clone $GITREPO
   bash reddit-wiki/aws/$ENV_STATUS/ec2/defaults.sh
   bash reddit-wiki/aws/$ENV_STATUS/ec2/access-$ENV_STATUS-bastion/access-$ENV_STATUS-bastion-1a.sh
   mv reddit-wiki/aws/$ENV_STATUS/ec2/hosts /etc/hosts"
   
    INST_ID=""
    aws ec2 create-tags --resource $INST_ID --tag "Value=access-$ENV_STATUS-bastion-1a,Key=Name"

    aws ec2 create-image --instance-id $INST_ID --name access-stage-bastion-1a

3) access-stage-bastion-1b => second ssh instance. Change AMI_ID to AMI ID for access-stage-bastion-1a. Change INST_ID to returned instance ID.

    AMI_ID="CHANGE_TO_ABOVE"
    aws ec2 run-instances --image-id $AMI_ID --count 1 --instance-type $INST_TYPE --key-name $KEY_NAME --security-group-ids $SG_ID --subnet-id $SUB_ID --associate-public-ip-address --private-ip-address 10.0.1.7 --block-device-mappings "[{\"DeviceName\": \"/dev/sdh\",\"Ebs\":{\"VolumeSize\":$DISK_SIZE}}]" --iam-instance-profile Name=$S3_CONF --user-data '#!/usr/bin/bash
    hostnamectl set-hostname access-stage-bastion-1b
'\ "
    INST_ID="CHANGE_TO_ABOVE"
    aws ec2 create-tags --resource $INST_ID --tag "Value=access-$ENV_STATUS-bastion-1b,Key=Name"


4) config-stage-puppet-1a => our puppet server. Will be used for config management. 

    aws ec2 run-instances --image-id $AMI_ID --count 1 --instance-type $INST_TYPE --key-name $KEY_NAME --security-group-ids $SG_ID --subnet-id $SUB_ID --associate-public-ip-address --private-ip-address 10.0.1.14 --block-device-mappings "[{\"DeviceName\": \"/dev/sdh\",\"Ebs\":{\"VolumeSize\":$DISK_SIZE}}]" --iam-instance-profile Name=$S3_CONF --user-data '#!/usr/bin/bash

'\ "yum install git -y
   git clone $GITREPO
   bash reddit-wiki/aws/$ENV_STATUS/ec2/defaults.sh
   bash reddit-wiki/aws/$ENV_STATUS/ec2/config-$ENV_STATUS-puppet/config-$ENV_STATUS-puppet-1a.sh"

    INST_ID="CHANGE_TO_ABOVE_RETURNED_VALUE"
    aws ec2 create-tags --resource $INST_ID --tag "Value=config-$ENV_STATUS-puppet-1a,Key=Name"

5) storage-stage-nfs-1a => this server will be used to store credentials and other temporary information. 


    aws ec2 run-instances --image-id $AMI_ID --count 1 --instance-type $INST_TYPE --key-name $KEY_NAME --security-group-ids $SG_ID --subnet-id $SUB_ID --associate-public-ip-address --private-ip-address 10.0.1.23 --block-device-mappings "[{\"DeviceName\": \"/dev/sdh\",\"Ebs\":{\"VolumeSize\":$DISK_SIZE}}]" --iam-instance-profile Name=$S3_CONF --user-data '#!/usr/bin/bash

'\ "yum install git -y
   git clone $GITREPO
   bash reddit-wiki/aws/$ENV_STATUS/ec2/defaults.sh
   bash reddit-wiki/aws/$ENV_STATUS/ec2/storage-$ENV_STATUS-nfs/storage-$ENV_STATUS-nfs-1a.sh"

    INST_ID="CHANGE_TO_ABOVE_RETURNED_VALUE"
    aws ec2 create-tags --resource $INST_ID --tag "Value=config-$ENV_STATUS-puppet-1a,Key=Name"

### Bootstrapping

Our instances need to be able to do two things: change their hostnames. Bootstrap themselves to the master. 

### Common Commands

Listing things (apply Name=tag:Name,Values="myvalue" filter for any given describe option)

0) List all available items for querying for $INST_NAME

    aws ec2 describe-instances --filters "Name=tag:Name,Values=$INST_NAME" --output text --query 'Reservations[*]'

1) Grab private IP address of an instance with the name "$INST_NAME" 

    aws ec2 describe-instances --filters "Name=tag:Name,Values=$INST_NAME" --output text --query 'Reservations[*].Instances[*].PrivateIpAddress'

2) Grab instance ID 

    aws ec2 describe-instances --filters "Name=tag:Name,Values=$INST_NAME" --output text --query 'Reservations[*].Instances[*].InstanceId'

3) List instance state 

    aws ec2 describe-instance-status --instance-ids $INST_ID --output text --query 'InstanceStatuses[*].InstanceState'

4) List groups of servers

    aws ec2 describe-instances 2>&1|grep access -B30|egrep -i "instances|tags" |awk '{print $7, $3}'|awk '{print $1}'

    aws ec2 describe-instances 2>&1|grep access -B30|egrep -i "instances|tags" |awk '{print $7}'|awk '{print $1}'|egrep "[a-z]|[0-9]"



### Fixing mistakes 

1) Delete instance

    aws ec2 terminate-instances --instance-ids $INST_ID 
    

### Terraform


### ToDo

Create 10.0.1.0/24 VPC and security group.

### LINKS

Config files: https://github.com/SouthernAirTemple/reddit-wiki/tree/master/aws 

AWS CLI Reference: http://docs.aws.amazon.com/cli/latest/reference
